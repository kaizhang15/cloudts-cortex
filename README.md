## CloudTS Cortex Integration

This work implementation is based on Cortex v1.16.0 and Prometheus v2.48.0.



### Get Start

To get start to work with CloudTS, it is recommended to first run pure Cortex, Prometheus and Node Exporter to say "hello world".

For Cortex and Prometheus, please find the source code from github ([Cortex v1.16.0](https://github.com/cortexproject/cortex/tree/v1.16.0), [Prometheus v2.48.0](https://github.com/prometheus/prometheus/tree/v2.48.0).

For Node Exporter, please install it with release package [Node Exporter](https://github.com/prometheus/node_exporter/releases?q=1.7.0&expanded=true).

To build these source code, you need:

- Go [version 1.17 or greater](https://golang.org/doc/install).
- NodeJS [version 16 or greater](https://nodejs.org/).
- npm [version 7 or greater](https://www.npmjs.com/).

For Node Exporter, please run it as follows:

```
tar -xzf node_exporter-1.7.0.linux-amd64.tar.gz
cd node_exporter-1.7.0.linux-amd64
cp node_exporter-1.7.0.linux-amd64/node_exporter /usr/local/bin/
node_exporter
```

For Prometheus, please build and run it as follows:

```
cd prometheus (github clone directory)
make build
./prometheus --config.file=./documentation/examples/prometheus.yml
```

For Cortex, please build it as follows:

```
cd cortex (github clone directory)
go build ./cmd/cortex
./cortex -config.file=./docs/configuration/single-process-config.yaml
```

To collect data from Node Exporter, you need to modify the configuration files of Prometheus.

For prometheus.yml, add following under scrape_configs and remote_write

```
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
  # Collect node exporter data
  - job_name: 'node'
    static_configs:
      - targets: ['localhost:9100']
remote_write:
- url: http://localhost:9009/api/prom/push
```

Then you may find the monitoring data is collected by Prometheus an Cortex.



To run CloudTS with cortex, it has the same build steps.

For CloudTS, it has more configuration options as listed below:

```
cloudts:
  s3:
    bucket: my-bucket
    region: region_exp
    access_key: xxxxxxx
    secret_key: xxxxxxx
    endpoint: http://minio:9000
  partition_duration: 2h
  max_upload_connections: 5
  
```




### Evaluation

The evaluation is based on EC2 m5.2xlarge server, with Ubuntu 22.04 LTS and S3 storage.

For the production environment, data can be collected as described above and you can execute query with http api provided by Cortex (https://cortexmetrics.io/docs/api/#range-query).



For the synthetic workload, more node exporters should be utilized to generate data (50 node exporters on 10 virtual machines, you need change the node_exporters port to support more node exporters), and we follow the query patterns as described in the paper to evaluate the performance.

These query patterns are generated by [TSBS](https://github.com/timescale/tsbs). 